import streamlit as st
import requests
from bs4 import BeautifulSoup
from PIL import Image
import re

st.set_page_config(page_title="–ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–ø–æ–∏—Å–∫–æ–≤–∏–∫", layout="wide")

class InternetResearchAI:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
    
    def get_page_content(self, url: str):
        try:
            response = self.session.get(url, timeout=10)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            for tag in soup.find_all(['script', 'style', 'nav', 'footer', 'header']):
                tag.decompose()
            
            text = soup.get_text()
            text = re.sub(r'\s+', ' ', text)
            return text[:2000]
        except:
            return ""
    
    def extract_text_from_image(self, image):
        try:
            width, height = image.size
            return f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {width}x{height} –ø–∏–∫—Å–µ–ª–µ–π. –î–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–±—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫."
        except:
            return "–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"

def main():
    st.title("üß† –£–º–Ω—ã–π –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–ø–æ–∏—Å–∫–æ–≤–∏–∫")
    st.write("–ê–Ω–∞–ª–∏–∑ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    research_ai = InternetResearchAI()
    
    option = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é:", 
                     ["üìù –ê–Ω–∞–ª–∏–∑ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã", "üì∑ –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"])
    
    if option == "üìù –ê–Ω–∞–ª–∏–∑ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã":
        st.header("–ê–Ω–∞–ª–∏–∑ –≤–µ–±-—Å—Ç—Ä–∞–Ω–∏—Ü—ã")
        url = st.text_input("–í–≤–µ–¥–∏—Ç–µ URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã:", 
                          placeholder="https://example.com")
        
        if st.button("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å") and url:
            with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É..."):
                content = research_ai.get_page_content(url)
                
                if content:
                    st.success("–°—Ç—Ä–∞–Ω–∏—Ü–∞ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞!")
                    st.write("**–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:**", content[:1000] + "...")
                else:
                    st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã")
    
    else:
        st.header("–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        
        uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", 
                                       type=['png', 'jpg', 'jpeg'])
        
        if uploaded_file is not None:
            try:
                image = Image.open(uploaded_file)
                st.image(image, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_column_width=True)
                
                if st.button("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"):
                    with st.spinner("–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ..."):
                        image_info = research_ai.extract_text_from_image(image)
                        
                        st.subheader("üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏:")
                        st.write(image_info)
                        
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")

if __name__ == "__main__":
    main()